{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C02UCHvxwh8c"
      },
      "source": [
        "```\n",
        "Copyright 2022 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HWpgjkuv1fH"
      },
      "source": [
        "# Melting Pot Evaluation Results\n",
        "\n",
        "This Colab plots results of the MAPLA evaluations outlined in the [Melting Pot 2.0 Tech Report](https://arxiv.org/abs/2211.13746).\n",
        "\n",
        "1.  Click \"Connect\" in the top right corner.\n",
        "2.  Select \"Runtime -\u003e Run all\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IxxEhtumBUKO"
      },
      "outputs": [],
      "source": [
        "# @title Installs\n",
        "\n",
        "%pip install --quiet colabtools\n",
        "%pip install --quiet matplotlib\n",
        "%pip install --quiet numpy\n",
        "%pip install --quiet pandas\n",
        "%pip install --quiet seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XcuVeMOyZgSH"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import dataclasses\n",
        "import re\n",
        "import sys\n",
        "from unittest import mock\n",
        "import urllib\n",
        "\n",
        "import IPython\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mabOJPluAhJE"
      },
      "outputs": [],
      "source": [
        "# @title Setup\n",
        "\n",
        "def no_vertical_scrollbar():\n",
        "  \"\"\"Disable scroll-in-the-scroll.\"\"\"\n",
        "  javascript = 'google.colab.output.setIframeHeight(0, true, {interactive: true, maxHeight: 9999})'\n",
        "  display(IPython.display.Javascript(javascript))\n",
        "\n",
        "\n",
        "# No vertical scrollbars.\n",
        "get_ipython().events.register('pre_run_cell', no_vertical_scrollbar)\n",
        "\n",
        "# Allow higher resolution plots.\n",
        "IPython.display.set_matplotlib_formats('retina')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-qiw4ao-UgXT"
      },
      "outputs": [],
      "source": [
        "# @title Utilities\n",
        "\n",
        "def display(dataframe):\n",
        "  \"\"\"Displays dataframe, regardless of size.\n",
        "\n",
        "  Args:\n",
        "    dataframe: dataframe to display.\n",
        "  \"\"\"\n",
        "  with pd.option_context('display.max_rows', None, 'display.max_columns', None,\n",
        "                         'display.max_colwidth', None):\n",
        "    IPython.display.display(dataframe)\n",
        "\n",
        "\n",
        "def _heatmap(data, **kwargs):\n",
        "  \"\"\"Plots a heatmap of the data.\n",
        "\n",
        "  Args:\n",
        "    data: Data to plot\n",
        "    **kwargs: forwarded to sns.heatmap\n",
        "\n",
        "  Returns:\n",
        "    The axes of the heatmap.\n",
        "  \"\"\"\n",
        "  max_abs_value = np.nanmax(np.abs(data))\n",
        "  kwargs.setdefault('cbar', False)\n",
        "  kwargs.setdefault('linewidth', 1)\n",
        "  kwargs.setdefault('annot', True)\n",
        "  if max_abs_value \u003e= 10000:\n",
        "    kwargs.setdefault('fmt', '.1g')\n",
        "  elif max_abs_value \u003e= 100:\n",
        "    kwargs.setdefault('fmt', '.0f')\n",
        "  elif max_abs_value \u003e= 10:\n",
        "    kwargs.setdefault('fmt', '.1f')\n",
        "  else:\n",
        "    kwargs.setdefault('fmt', '.2f')\n",
        "\n",
        "  ax = sns.heatmap(data, **kwargs)\n",
        "  plt.tick_params(\n",
        "      which='both', left=False, right=False, bottom=False, top=False)\n",
        "  plt.setp([tick.label1 for tick in ax.xaxis.get_major_ticks()],\n",
        "           rotation=45,\n",
        "           ha='right',\n",
        "           va='center',\n",
        "           rotation_mode='anchor')\n",
        "  plt.setp([tick.label2 for tick in ax.xaxis.get_major_ticks()],\n",
        "           rotation=45,\n",
        "           ha='left',\n",
        "           va='center',\n",
        "           rotation_mode='anchor')\n",
        "  return ax\n",
        "\n",
        "\n",
        "def heatmap(data, left=None, right=None, top=None, bottom=None, **kwargs):\n",
        "  row_labels = list(data.index)\n",
        "  col_labels = list(data.columns)\n",
        "  data = data.to_numpy()\n",
        "\n",
        "  if top is None:\n",
        "    top_rows = 0\n",
        "  elif not top.empty:\n",
        "    row_labels = list(top.index) + [''] + row_labels\n",
        "    data = np.vstack([\n",
        "        top.to_numpy(),\n",
        "        np.zeros(top.iloc[0].shape) + np.nan,\n",
        "        data,\n",
        "    ])\n",
        "    top_rows = top.shape[0] + 1\n",
        "\n",
        "  if bottom is None:\n",
        "    bottom_rows = 0\n",
        "  elif not bottom.empty:\n",
        "    row_labels = row_labels + [''] + list(bottom.index)\n",
        "    data = np.vstack([\n",
        "        data,\n",
        "        np.zeros(bottom.iloc[0].shape) + np.nan,\n",
        "        bottom.to_numpy(),\n",
        "    ])\n",
        "    bottom_rows = bottom.shape[0] + 1\n",
        "\n",
        "  if left is None:\n",
        "    pass\n",
        "  elif not left.empty:\n",
        "    col_labels = list(left.columns) + [''] + col_labels\n",
        "    data = np.hstack([\n",
        "        np.vstack([\n",
        "            np.zeros([top_rows, left.shape[1]]) + np.nan,\n",
        "            left.to_numpy(),\n",
        "            np.zeros([bottom_rows, left.shape[1]]) + np.nan,\n",
        "        ]),\n",
        "        np.zeros([data.shape[0], 1]) + np.nan,\n",
        "        data,\n",
        "    ])\n",
        "\n",
        "  if right is None:\n",
        "    pass\n",
        "  elif not top.empty:\n",
        "    col_labels = col_labels + [''] + list(right.columns)\n",
        "    data = np.hstack([\n",
        "        data,\n",
        "        np.zeros([data.shape[0], 1]) + np.nan,\n",
        "        np.vstack([\n",
        "            np.zeros([top_rows, right.shape[1]]) + np.nan,\n",
        "            right.to_numpy(),\n",
        "            np.zeros([bottom_rows, right.shape[1]]) + np.nan,\n",
        "        ]),\n",
        "    ])\n",
        "\n",
        "  with plt.rc_context({\n",
        "      'font.size': 15,\n",
        "      'xtick.labeltop': True,\n",
        "      'xtick.labelbottom': True,\n",
        "      'ytick.labelleft': True,\n",
        "      'ytick.labelright': True,\n",
        "  }):\n",
        "    plt.figure(figsize=(data.shape[1], data.shape[0] * 0.6))\n",
        "    kwargs.setdefault('vmin', 0)\n",
        "    kwargs.setdefault('vmax', 1)\n",
        "    kwargs.setdefault('cmap', 'coolwarm')\n",
        "    return _heatmap(\n",
        "        data=data,\n",
        "        xticklabels=col_labels,\n",
        "        yticklabels=row_labels,\n",
        "        **kwargs,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F7wd3g6IR8-t"
      },
      "outputs": [],
      "source": [
        "# @title Load results\n",
        "path = 'https://storage.googleapis.com/dm-meltingpot/meltingpot-results-2.1.0.feather'  # @param {type: 'string'}\n",
        "results = pd.read_feather(path)\n",
        "scenario_results = results.drop(\n",
        "    labels=set(results.substrate.unique()),\n",
        "    axis=1,\n",
        "    errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stuzqe8KFYmQ"
      },
      "source": [
        "## Calculate scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "85YmhzAE1xX0"
      },
      "outputs": [],
      "source": [
        "# @title Aggregate focal_per_capita_return over episodes\n",
        "\n",
        "def summarize(results):\n",
        "  grouped = scenario_results.groupby(\n",
        "      ['scenario', 'substrate', 'mapla', 'training_run'])\n",
        "  df = grouped.focal_per_capita_return.agg(\n",
        "      ['count', 'mean', 'std', 'sem'], axis=1)\n",
        "  return df\n",
        "\n",
        "\n",
        "performance_per_run = summarize(scenario_results)\n",
        "performance_per_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m76CSuuNKX__"
      },
      "outputs": [],
      "source": [
        "# @title Normalize focal_per_capita_return statistics\n",
        "\n",
        "def normalize(performance_per_run):\n",
        "  raw = performance_per_run.unstack(['mapla', 'training_run'])\n",
        "  lower = raw['mean'].min(axis=1) - 1e-8\n",
        "  upper = raw['mean'].max(axis=1)\n",
        "  scale = upper - lower\n",
        "\n",
        "  normalized = raw.assign(\n",
        "      mean=raw['mean'].subtract(lower, axis=0).divide(scale, axis=0),\n",
        "      std=raw['std'].divide(scale, axis=0),\n",
        "      sem=raw['sem'].divide(scale, axis=0),\n",
        "  )\n",
        "  normalized = normalized.stack(['mapla', 'training_run'])\n",
        "  normalized = normalized.sort_index()\n",
        "  return normalized\n",
        "\n",
        "\n",
        "scenario_scores_per_run = normalize(performance_per_run)\n",
        "scenario_scores_per_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1v0rvkuW0C7p"
      },
      "outputs": [],
      "source": [
        "# @title Make assumptions about missing prosocial runs\n",
        "\n",
        "print(\"\"\"\n",
        "NOTE: For the collective-return substrates, the prosocial MAPLA receive rewards \n",
        "identical to those received by a non-prosocial variants (except for a scale\n",
        "factor). Thus, for these substrates, the prosocial MAPLA is identical to the\n",
        "non-prosocial variant, and we expect they would therefore achieved the same\n",
        "performance. We therefore copy the non-prosocial scores for this situation.\n",
        "\"\"\")\n",
        "\n",
        "_COLLECTIVE_RETURN_SUBSTATES = frozenset({\n",
        "    'collaborative_cooking__asymmetric',\n",
        "    'collaborative_cooking__circuit',\n",
        "    'collaborative_cooking__cramped',\n",
        "    'collaborative_cooking__crowded',\n",
        "    'collaborative_cooking__figure_eight',\n",
        "    'collaborative_cooking__forced',\n",
        "    'collaborative_cooking__ring',\n",
        "})\n",
        "\n",
        "\n",
        "def _add_prosocial_performance(scenario_scores_per_run):\n",
        "  df = scenario_scores_per_run.reset_index()\n",
        "  df = df[df.substrate.isin(_COLLECTIVE_RETURN_SUBSTATES)]\n",
        "  df = df[df.mapla.isin(['acb', 'opre'])]\n",
        "  df = df.assign(mapla=df.mapla.map(lambda x: x + '_prosocial'))\n",
        "  df = df.set_index(['scenario', 'substrate', 'mapla', 'training_run'])\n",
        "  return pd.concat([scenario_scores_per_run, df]).sort_index()\n",
        "\n",
        "\n",
        "scenario_scores_per_run = _add_prosocial_performance(scenario_scores_per_run)\n",
        "scenario_scores_per_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1JnIN6yiYZ0w"
      },
      "outputs": [],
      "source": [
        "# @title Aggregate per-scenario scores over training runs\n",
        "\n",
        "scores_per_scenario = scenario_scores_per_run['mean']\n",
        "scores_per_scenario = scores_per_scenario.groupby(['scenario', 'substrate', 'mapla']).agg(['count', 'mean', 'std', 'sem'])\n",
        "scores_per_scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R1ZgicDs3zqL"
      },
      "outputs": [],
      "source": [
        "# @title Count number of scenarios for each substrate\n",
        "\n",
        "scenarios_per_substrate = scores_per_scenario.reset_index(['mapla', 'scenario']).scenario  #['scenario'] #drop_duplicates()\n",
        "scenarios_per_substrate = scenarios_per_substrate.groupby(level='substrate').nunique()\n",
        "scenarios_per_substrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vgB1zwOMmNMO"
      },
      "outputs": [],
      "source": [
        "# @title Aggregate per-substrate scores over training runs\n",
        "\n",
        "scores_per_substrate = scenario_scores_per_run['mean']\n",
        "scores_per_substrate = scores_per_substrate.unstack(['scenario'])\n",
        "scores_per_substrate = scores_per_substrate.sum(axis=1).div(scenarios_per_substrate)\n",
        "scores_per_substrate = scores_per_substrate.groupby(['substrate', 'mapla']).agg(['count', 'mean', 'std', 'sem'])\n",
        "scores_per_substrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X51fkwtqvY6g"
      },
      "outputs": [],
      "source": [
        "# @title Aggregate overall scores over training runs\n",
        "\n",
        "overall_scores = scenario_scores_per_run['mean']\n",
        "overall_scores = overall_scores.unstack(['scenario'])\n",
        "overall_scores = overall_scores.sum(axis=1).div(scenarios_per_substrate)\n",
        "overall_scores = overall_scores.unstack(['substrate'])\n",
        "overall_scores = overall_scores.sum(axis=1).div(len(scenarios_per_substrate))\n",
        "overall_scores = overall_scores.groupby(['mapla']).agg(['count', 'mean', 'std', 'sem'])\n",
        "overall_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K9SdhF0FcXe"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fXRcA1ketAqn"
      },
      "outputs": [],
      "source": [
        "# @title Plot scores\n",
        "\n",
        "def _plot_scores():\n",
        "  score = overall_scores['mean']\n",
        "  score = score.sort_values(ascending=False)\n",
        "  per_substrate = scores_per_substrate['mean'].unstack('mapla')\n",
        "  per_substrate = per_substrate.reindex(columns=score.index)\n",
        "  per_scenario = scores_per_scenario['mean'].unstack('mapla')\n",
        "  per_scenario = per_scenario.reindex(columns=score.index)\n",
        "\n",
        "  tabs = widgets.TabBar(['summary', 'breakdown'])\n",
        "\n",
        "  with tabs.output_to('summary'):\n",
        "    top = pd.DataFrame.from_dict({'overall score': score}, orient='index')\n",
        "    heatmap(per_substrate, top=top)\n",
        "\n",
        "  with tabs.output_to('breakdown', select=False):\n",
        "    substrates = per_scenario.index.unique('substrate')\n",
        "    subtabs = widgets.TabBar(list(substrates))\n",
        "    for substrate, df in per_scenario.groupby(level='substrate'):\n",
        "      with subtabs.output_to(substrate, select=False):\n",
        "        df = df.droplevel('substrate')\n",
        "\n",
        "        top = pd.DataFrame.from_dict({\n",
        "            'all substrates': score,\n",
        "            substrate: per_substrate.loc[substrate]\n",
        "        }, orient='index')\n",
        "        heatmap(df, top=top)\n",
        "\n",
        "\n",
        "_plot_scores()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "stuzqe8KFYmQ"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
